{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1e2b3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras as kr\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ced4f021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5ae8d38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.08.31</td>\n",
       "      <td>10:00</td>\n",
       "      <td>1.25120</td>\n",
       "      <td>1.25463</td>\n",
       "      <td>1.25117</td>\n",
       "      <td>1.25463</td>\n",
       "      <td>3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.08.31</td>\n",
       "      <td>11:00</td>\n",
       "      <td>1.25462</td>\n",
       "      <td>1.25804</td>\n",
       "      <td>1.25449</td>\n",
       "      <td>1.25660</td>\n",
       "      <td>4202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.08.31</td>\n",
       "      <td>12:00</td>\n",
       "      <td>1.25660</td>\n",
       "      <td>1.25936</td>\n",
       "      <td>1.25596</td>\n",
       "      <td>1.25825</td>\n",
       "      <td>4381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012.08.31</td>\n",
       "      <td>13:00</td>\n",
       "      <td>1.25825</td>\n",
       "      <td>1.25917</td>\n",
       "      <td>1.25751</td>\n",
       "      <td>1.25916</td>\n",
       "      <td>3590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.08.31</td>\n",
       "      <td>14:00</td>\n",
       "      <td>1.25916</td>\n",
       "      <td>1.26269</td>\n",
       "      <td>1.25877</td>\n",
       "      <td>1.26104</td>\n",
       "      <td>4922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64995</th>\n",
       "      <td>2023.02.24</td>\n",
       "      <td>19:00</td>\n",
       "      <td>1.05440</td>\n",
       "      <td>1.05589</td>\n",
       "      <td>1.05431</td>\n",
       "      <td>1.05472</td>\n",
       "      <td>4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64996</th>\n",
       "      <td>2023.02.24</td>\n",
       "      <td>20:00</td>\n",
       "      <td>1.05472</td>\n",
       "      <td>1.05552</td>\n",
       "      <td>1.05441</td>\n",
       "      <td>1.05453</td>\n",
       "      <td>3812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64997</th>\n",
       "      <td>2023.02.24</td>\n",
       "      <td>21:00</td>\n",
       "      <td>1.05453</td>\n",
       "      <td>1.05544</td>\n",
       "      <td>1.05441</td>\n",
       "      <td>1.05509</td>\n",
       "      <td>3394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64998</th>\n",
       "      <td>2023.02.24</td>\n",
       "      <td>22:00</td>\n",
       "      <td>1.05507</td>\n",
       "      <td>1.05557</td>\n",
       "      <td>1.05465</td>\n",
       "      <td>1.05472</td>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64999</th>\n",
       "      <td>2023.02.24</td>\n",
       "      <td>23:00</td>\n",
       "      <td>1.05471</td>\n",
       "      <td>1.05486</td>\n",
       "      <td>1.05431</td>\n",
       "      <td>1.05433</td>\n",
       "      <td>1124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date   time     open     high      low    close  volume\n",
       "0      2012.08.31  10:00  1.25120  1.25463  1.25117  1.25463    3635\n",
       "1      2012.08.31  11:00  1.25462  1.25804  1.25449  1.25660    4202\n",
       "2      2012.08.31  12:00  1.25660  1.25936  1.25596  1.25825    4381\n",
       "3      2012.08.31  13:00  1.25825  1.25917  1.25751  1.25916    3590\n",
       "4      2012.08.31  14:00  1.25916  1.26269  1.25877  1.26104    4922\n",
       "...           ...    ...      ...      ...      ...      ...     ...\n",
       "64995  2023.02.24  19:00  1.05440  1.05589  1.05431  1.05472    4280\n",
       "64996  2023.02.24  20:00  1.05472  1.05552  1.05441  1.05453    3812\n",
       "64997  2023.02.24  21:00  1.05453  1.05544  1.05441  1.05509    3394\n",
       "64998  2023.02.24  22:00  1.05507  1.05557  1.05465  1.05472    3683\n",
       "64999  2023.02.24  23:00  1.05471  1.05486  1.05431  1.05433    1124\n",
       "\n",
       "[65000 rows x 7 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data \n",
    "data = pd.read_csv('EURUSD60.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3421366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger = data[\"open\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4d44f659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65000,)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we scale the data between 0 to 1\n",
    "opendata = data[\"open\"]\n",
    "opendatas = opendata/bigger\n",
    "opendatas.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "02dde39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this fun for divide the data into 2 matrex on eis the input and the other is the output data \n",
    "#we can manapelate in the raws and columns to get 3d or 2d array in this code we get 3d array\n",
    "#we can also get one or more features here\n",
    "def create_dataset(x_data,y_data, look_back=1):\n",
    "    X,Y = [],[] \n",
    "    for i in range(len(y_data) - look_back): \n",
    "        X.append(x_data[i:i + look_back])\n",
    "        Y.append(y_data[i + look_back])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1b8cccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#هاي الفنكشن نسوي مصفوفة من الواحدات و الصفار حسب حركة السعر بنقاط معينه نحددها \n",
    "def moving (opendata):   \n",
    "    stop_p =0       #النقطة الي راح نوكف عدها عند تحرك السعر بالقيمة المطلوبه\n",
    "    pip_point = 0.0001   #حجم النقطة\n",
    "    pip = 50 * pip_point    #النقاط الي راح يتحرك بيها السعر\n",
    "    y =[]\n",
    "    start_c = opendata[0] #السعر من النقطة المطلوب الحساب منها \n",
    "    for candle in range(len(opendata)):\n",
    "        n_diff = opendata[candle] - start_c    #الفرق الذي تحرك به السعر\n",
    "        if (n_diff>= pip):\n",
    "            for ones in range(candle - stop_p): #ضيف واحدات\n",
    "                y.append(1)\n",
    "            start_c = opendata[candle]\n",
    "            stop_p = candle\n",
    "        if (n_diff <= -pip):\n",
    "            for zeros in range (candle - stop_p):  #ضيف صفار\n",
    "                   y.append(0)\n",
    "            start_c = opendata[candle]\n",
    "            stop_p = candle\n",
    "    return np.array(y)   #رجع نمابي اري"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1e245121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64993, 1)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we get the y array \n",
    "y_data = moving(opendata)\n",
    "y_datas = y_data.reshape(-1,1)\n",
    "y_datas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "064300a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64993,)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we convert the csv file into np array also we delete the first raw we dont need if its zeros\n",
    "opendatas1 = np.array(opendatas)\n",
    "opendatas2 = opendatas1[:-7] #y and x must be equal, y doesnt equal x cuase the moving fun the last elemints didnt make the if conditional\n",
    "#opendatas3 = opendatas2.reshape(-1,1) #reshape it to 2d array here we use -1 to auto determine the sample in 1d array\n",
    "opendatas2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ae158741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64973, 20)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the lookback we can use to get how many timesteps to predicts the next timesteps\n",
    "look_back = 20\n",
    "x_data,y_data = create_dataset(opendatas2,y_data,look_back)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9da4c4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64973, 1)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data.reshape(-1,1)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "37ca600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trsize = int(0.8*len(x_data))\n",
    "\n",
    "y_trsize = int(0.8*len(y_data))\n",
    "\n",
    "\n",
    "x_train = x_data[42:x_trsize]\n",
    "x_test = x_data[x_trsize:]\n",
    "y_train = y_data[42:y_trsize]\n",
    "y_test =y_data[y_trsize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "bce2b7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12995, 20)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b1c32752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51936, 20)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "83607d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51936, 1)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5cf45194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12995, 1)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4be0709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 20), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 96\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(len(x_train)).batch(BATCH_SIZE)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e6956d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23179"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model hyperparameters\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "input_vocab_size = target_vocab_size = len(np.unique(x_train))\n",
    "dropout_rate = 0.1\n",
    "input_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "dd6555c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = 1 / tf.pow(10000, tf.range(0, d_model, 2, dtype=tf.float32) / tf.cast(d_model, tf.float32))\n",
    "    angle_rads = tf.expand_dims(angle_rads, 0)\n",
    "    angle_rads = tf.expand_dims(angle_rads, 0)\n",
    "\n",
    "    pos = tf.range(position, dtype=tf.float32)\n",
    "    pos = tf.expand_dims(pos, 1)\n",
    "\n",
    "    pos_encoding = pos * angle_rads\n",
    "\n",
    "    pos_encoding = tf.concat([tf.sin(pos_encoding[:, 0::2]), tf.cos(pos_encoding[:, 1::2])], axis=-1)\n",
    "\n",
    "    return pos_encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "226c05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled dot-product attention\n",
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c12298d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-head attention\n",
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = layers.Dense(d_model)\n",
    "        self.wk = layers.Dense(d_model)\n",
    "        self.wv = layers.Dense(d_model)\n",
    "\n",
    "        self.dense = layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "\n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a82115a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward neural network\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Dense(dff, activation='relu'),\n",
    "        layers.Dense(d_model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cea18504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder layer\n",
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "597743ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder layer\n",
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        self.dropout3 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9504f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Encoder\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "80228f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decoder\n",
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "            attention_weights[f'decoder_layer{i + 1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i + 1}_block2'] = block2\n",
    "\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d972d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Transformer model\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b772762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters and build the model\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size,\n",
    "                          pe_input=input_vocab_size+1,\n",
    "                          pe_target=target_vocab_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "34c13ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage:\n",
    "# Define the loss function and optimizer\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "efd81bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the masks\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    \n",
    "    enc_padding_mask = tf.math.logical_not(tf.math.equal(inp, 0))\n",
    "    enc_padding_mask = tf.cast(enc_padding_mask, dtype=tf.float32)\n",
    "    enc_padding_mask = enc_padding_mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, inp_seq_len)\n",
    "\n",
    "    # Decoder padding mask\n",
    "    dec_padding_mask = tf.math.logical_not(tf.math.equal(tar, 0))\n",
    "    dec_padding_mask = tf.cast(dec_padding_mask, dtype=tf.float32)\n",
    "    dec_padding_mask = dec_padding_mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, tar_seq_len)\n",
    "\n",
    "    # Look-ahead mask for the Decoder\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((tf.shape(tar)[1], tf.shape(tar)[1])), -1, 0)\n",
    "    look_ahead_mask = look_ahead_mask[tf.newaxis, tf.newaxis, :, :]  # (1, 1, tar_seq_len, tar_seq_len)\n",
    "\n",
    "    # Combined mask for the Decoder (both padding and look-ahead)\n",
    "    combined_mask = tf.maximum(dec_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "4971b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    #tar_inp = tar[:, :-1]\n",
    "    #tar_real = tar[:, 1:] \n",
    "    #if batch == len(train_dataset)-1:\n",
    "        #break\n",
    "    \n",
    "    #enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "    \n",
    "    #print(tar)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "72ea87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage:\n",
    "# Implement training loop (note: data preparation and batching not included in this example)\n",
    "def train_step(inp, tar):\n",
    "\n",
    "    \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "   \n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar, True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
    "        \n",
    "        loss = loss_function(tar, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "635ce6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.0013\n",
      "Epoch 1 Batch 100 Loss 0.0009\n",
      "Epoch 1 Batch 200 Loss 0.0007\n",
      "Epoch 1 Batch 300 Loss 0.0006\n",
      "Epoch 1 Batch 400 Loss 0.0005\n",
      "Epoch 1 Batch 500 Loss 0.0004\n",
      "Epoch 1 Loss 0.0007\n",
      "Epoch 2 Batch 0 Loss 0.0004\n",
      "Epoch 2 Batch 100 Loss 0.0003\n",
      "Epoch 2 Batch 200 Loss 0.0003\n",
      "Epoch 2 Batch 300 Loss 0.0002\n",
      "Epoch 2 Batch 400 Loss 0.0002\n",
      "Epoch 2 Batch 500 Loss 0.0002\n",
      "Epoch 2 Loss 0.0003\n",
      "Epoch 3 Batch 0 Loss 0.0002\n",
      "Epoch 3 Batch 100 Loss 0.0002\n",
      "Epoch 3 Batch 200 Loss 0.0001\n",
      "Epoch 3 Batch 300 Loss 0.0001\n",
      "Epoch 3 Batch 400 Loss 0.0001\n",
      "Epoch 3 Batch 500 Loss 0.0001\n",
      "Epoch 3 Loss 0.0001\n",
      "Epoch 4 Batch 0 Loss 0.0001\n",
      "Epoch 4 Batch 100 Loss 0.0001\n",
      "Epoch 4 Batch 200 Loss 0.0001\n",
      "Epoch 4 Batch 300 Loss 0.0001\n",
      "Epoch 4 Batch 400 Loss 0.0001\n",
      "Epoch 4 Batch 500 Loss 0.0001\n",
      "Epoch 4 Loss 0.0001\n",
      "Epoch 5 Batch 0 Loss 0.0001\n",
      "Epoch 5 Batch 100 Loss 0.0000\n",
      "Epoch 5 Batch 200 Loss 0.0000\n",
      "Epoch 5 Batch 300 Loss 0.0000\n",
      "Epoch 5 Batch 400 Loss 0.0000\n",
      "Epoch 5 Batch 500 Loss 0.0000\n",
      "Epoch 5 Loss 0.0000\n",
      "Epoch 6 Batch 0 Loss 0.0000\n",
      "Epoch 6 Batch 100 Loss 0.0000\n",
      "Epoch 6 Batch 200 Loss 0.0000\n",
      "Epoch 6 Batch 300 Loss 0.0000\n",
      "Epoch 6 Batch 400 Loss 0.0000\n",
      "Epoch 6 Batch 500 Loss 0.0000\n",
      "Epoch 6 Loss 0.0000\n",
      "Epoch 7 Batch 0 Loss 0.0000\n",
      "Epoch 7 Batch 100 Loss 0.0000\n",
      "Epoch 7 Batch 200 Loss 0.0000\n",
      "Epoch 7 Batch 300 Loss 0.0000\n",
      "Epoch 7 Batch 400 Loss 0.0000\n",
      "Epoch 7 Batch 500 Loss 0.0000\n",
      "Epoch 7 Loss 0.0000\n",
      "Epoch 8 Batch 0 Loss 0.0000\n",
      "Epoch 8 Batch 100 Loss 0.0000\n",
      "Epoch 8 Batch 200 Loss 0.0000\n",
      "Epoch 8 Batch 300 Loss 0.0000\n",
      "Epoch 8 Batch 400 Loss 0.0000\n",
      "Epoch 8 Batch 500 Loss 0.0000\n",
      "Epoch 8 Loss 0.0000\n",
      "Epoch 9 Batch 0 Loss 0.0000\n",
      "Epoch 9 Batch 100 Loss 0.0000\n",
      "Epoch 9 Batch 200 Loss 0.0000\n",
      "Epoch 9 Batch 300 Loss 0.0000\n",
      "Epoch 9 Batch 400 Loss 0.0000\n",
      "Epoch 9 Batch 500 Loss 0.0000\n",
      "Epoch 9 Loss 0.0000\n",
      "Epoch 10 Batch 0 Loss 0.0000\n",
      "Epoch 10 Batch 100 Loss 0.0000\n",
      "Epoch 10 Batch 200 Loss 0.0000\n",
      "Epoch 10 Batch 300 Loss 0.0000\n",
      "Epoch 10 Batch 400 Loss 0.0000\n",
      "Epoch 10 Batch 500 Loss 0.0000\n",
      "Epoch 10 Loss 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Training the Transformer\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        if batch == len(train_dataset):\n",
    "            break\n",
    "        loss = train_step(inp, tar)\n",
    "        total_loss += loss\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1} Batch {batch} Loss {loss.numpy():.4f}\")\n",
    "\n",
    "    average_loss = total_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch + 1} Loss {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9ffc3515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_11_layer_call_fn, embedding_11_layer_call_and_return_conditional_losses, dropout_96_layer_call_fn, dropout_96_layer_call_and_return_conditional_losses, embedding_12_layer_call_fn while saving (showing 5 of 224). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_model\\assets\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002793AF16750> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002790F21C9D0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x0000027977C6E2D0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797ACB32D0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797AC9C3D0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797AC9F790> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797ACD7250> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797ACA3210> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797AC9C190> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x0000027955DC9E90> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797CEF6B90> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.MultiHeadAttention object at 0x000002797CEF7F50> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class '__main__.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model including its architecture, configuration, and weights\n",
    "transformer.save('transformer_model')\n",
    "\n",
    "# Load the model with custom class mapping to resolve naming conflicts\n",
    "loaded_transformer = tf.keras.models.load_model('transformer_model', custom_objects={\"MultiHeadAttention\": MultiHeadAttention})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ee163b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_transformer = tf.keras.models.load_model('transformer_model', custom_objects={\"MultiHeadAttention\": MultiHeadAttention})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e64f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
